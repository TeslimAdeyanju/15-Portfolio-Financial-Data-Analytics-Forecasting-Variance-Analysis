{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ“‚ Financial Data Analytics: Forecasting, Variance Analysis, and Customer Insights  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ“š 1. Introduction\n",
    "\n",
    "\n",
    "<div style=\"font-family: Avenir, sans-serif; font-size: 16px; line-height: 1.6; color: white; background-color: #333; padding: 10px; border-radius: 5px;\">\n",
    "This section deals with the purpose, and problem statement, and contribution of this project to the sphere of knowledge. The project overview is also discussed in this section.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Overview \n",
    "____\n",
    "This project leverages a **comprehensive financial dataset** containing **transaction records, customer details, and card information** spanning the **2010s decade**. The dataset is sourced from **Kaggle** and contains **1 million records** with **21 columns**. The dataset is used to perform **financial forecasting, variance analysis, and customer insights extraction**. \n",
    "\n",
    "ðŸ”— **Reference Dataset:** [Financial Transactions Dataset: Analytics (Kaggle)](https://www.kaggle.com)  \n",
    "\n",
    "The goal is to **demonstrate expertise in SQL, Python, Machine Learning, and Power BI** by performing:  \n",
    "- **Financial forecasting** for revenue and expense prediction.  \n",
    "- **Variance analysis** to compare budgeted vs. actual financials.  \n",
    "- **Customer insights extraction** for spending behavior segmentation.  \n",
    "- **Business intelligence reporting** using interactive dashboards.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Objectives \n",
    "___\n",
    "\n",
    "\n",
    "By leveraging SQL for data extraction and transformation, Python for machine learning, and Power BI for visualization, the project aims to provide actionable financial insights.\n",
    "\n",
    "- **Financial Forecasting:** The goal is to build predictive models to forecast future revenue and expenses using historical transaction data. This involves extracting and cleaning financial data with SQL, training time-series models (ARIMA, XGBoost, LSTMs), and evaluating model performance using metrics such as RMSE, MAPE, and RÂ² scores.\n",
    "\n",
    "- **Variance Analysis:** The project will compare budgeted vs. actual financial performance to identify key variance drivers. Using SQL, variance percentages will be calculated across customers, merchants, and spending categories. This analysis will help detect high-variance spending patterns and uncover seasonal trends impacting financial deviations.\n",
    "\n",
    "- **Customer Spending & Segmentation:** To understand customer behavior, clustering algorithms (K-Means, DBSCAN) will be used to categorize customers based on spending patterns. The analysis will differentiate between high-value and low-value customers by evaluating transaction trends and creating customer profiles based on spending frequency, transaction volume, and merchant categories.\n",
    "\n",
    "- **Business Intelligence & Reporting:** The final objective is to develop a Power BI dashboard for real-time financial tracking and variance monitoring. SQL-based financial data will be integrated into Power BI to design interactive visualizations for revenue, expense, and variance trends. The dashboard will provide financial decision-makers with insights into spending behavior, revenue trends, and key financial variances.\n",
    "\n",
    "By addressing these objectives, the project will demonstrate a strong foundation in SQL, Python, Machine Learning, and Power BI, ensuring a data-driven approach to financial analysis and forecasting.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ“š 2. Data Integration and SQL Setup\n",
    "\n",
    "<div style=\"font-family: Avenir, sans-serif; font-size: 16px; line-height: 1.6; color: white; background-color: #333; padding: 10px; border-radius: 5px;\">\n",
    "This section focuses on loading the financial transactions dataset into a SQL database, establishing relationships between tables, and ensuring data integrity. The SQL setup is crucial for subsequent data analysis, forecasting, and visualization tasks.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Dataset Schema & Relationships \n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset consists of multiple interconnected files, requiring structured relationships to ensure seamless data integration. The table below outlines the **primary keys, foreign keys, and purpose** of each dataset component.  \n",
    "\n",
    "| **Dataset**                | **Primary Key**     | **Foreign Key(s) & Relationships**           | **Purpose** |\n",
    "|----------------------------|--------------------|----------------------------------------------|-------------|\n",
    "| `transactions_data.csv`     | `transaction_id`   | `user_id`, `card_id`, `mcc_code`            | Tracks revenue, expenses, and spending details. |\n",
    "| `cards_data.csv`           | `card_id`          | `user_id`                                   | Links transactions to customers via cards. |\n",
    "| `users_data.csv`           | `user_id`          | None                                        | Provides user demographics and account details. |\n",
    "| `mcc_codes.json`           | `mcc_code`         | None                                        | Maps merchant category codes to business types. |\n",
    "| `train_fraud_labels.json`  | `transaction_id`   | None                                        | Labels transactions as fraudulent (1) or legitimate (0). |\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Overview\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Users Table:**   \n",
    "Contains key demographic and financial information such as current_age, retirement_age, income details, total_debt, and credit_score. These fields are crucial for profiling customers and can serve as features for predicting spending patterns, risk, and future financial behavior.\n",
    "\n",
    "2. **Cards Table:**   \n",
    "Links directly to the users table through user_id and provides additional insights into customer behavior by including details like card_brand, card_type, credit_limit, and security-related attributes (e.g., has_chip, card_on_dark_web). These features can be used to segment customers or detect anomalies in card usage.\n",
    "\n",
    "3. **MCC Codes Table:**   \n",
    "Offers a mapping of merchant category codes to their descriptions, which helps classify transactions. By integrating this table with transactions, you can derive categorical features that highlight spending trends across different merchant types.\n",
    "\n",
    "4. **Transactions Table:**   \n",
    "Serves as the central repository for tracking financial activity, linking users and cards. It records transaction dates, amounts, merchant details, and even error logs. With these, you can compute aggregated metrics (like total spending per customer or monthly revenue trends) and conduct variance analysis (budgeted vs. actual amounts).\n",
    "\n",
    "5. **Fraud Labels Table:**  \n",
    "Provides a target variable for supervised learning tasks, specifically fraud detection. By associating each transaction with a fraud label, you can build models to predict fraudulent behavior based on the integrated features from the other tables.\n",
    "\n",
    "The first step is to load the dataset into a SQL database and establish relationships between the tables to facilitate data retrieval and analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Loading \n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading dataset: users_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "current_age",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "retirement_age",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "birth_year",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "birth_month",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "gender",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "address",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "latitude",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "longitude",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "per_capita_income",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "yearly_income",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "total_debt",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "credit_score",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "num_credit_cards",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "ab1dd5e2-c642-4ce0-bd62-87de272f10ed",
       "rows": [
        [
         "0",
         "825",
         "53",
         "66",
         "1966",
         "11",
         "Female",
         "462 Rose Lane",
         "34.15",
         "-117.76",
         "$29278",
         "$59696",
         "$127613",
         "787",
         "5"
        ],
        [
         "1",
         "1746",
         "53",
         "68",
         "1966",
         "12",
         "Female",
         "3606 Federal Boulevard",
         "40.76",
         "-73.74",
         "$37891",
         "$77254",
         "$191349",
         "701",
         "5"
        ],
        [
         "2",
         "1718",
         "81",
         "67",
         "1938",
         "11",
         "Female",
         "766 Third Drive",
         "34.02",
         "-117.89",
         "$22681",
         "$33483",
         "$196",
         "698",
         "5"
        ],
        [
         "3",
         "708",
         "63",
         "63",
         "1957",
         "1",
         "Female",
         "3 Madison Street",
         "40.71",
         "-73.99",
         "$163145",
         "$249925",
         "$202328",
         "722",
         "4"
        ],
        [
         "4",
         "1164",
         "43",
         "70",
         "1976",
         "9",
         "Male",
         "9620 Valley Stream Drive",
         "37.76",
         "-122.44",
         "$53797",
         "$109687",
         "$183855",
         "675",
         "1"
        ]
       ],
       "shape": {
        "columns": 14,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>current_age</th>\n",
       "      <th>retirement_age</th>\n",
       "      <th>birth_year</th>\n",
       "      <th>birth_month</th>\n",
       "      <th>gender</th>\n",
       "      <th>address</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>per_capita_income</th>\n",
       "      <th>yearly_income</th>\n",
       "      <th>total_debt</th>\n",
       "      <th>credit_score</th>\n",
       "      <th>num_credit_cards</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>825</td>\n",
       "      <td>53</td>\n",
       "      <td>66</td>\n",
       "      <td>1966</td>\n",
       "      <td>11</td>\n",
       "      <td>Female</td>\n",
       "      <td>462 Rose Lane</td>\n",
       "      <td>34.15</td>\n",
       "      <td>-117.76</td>\n",
       "      <td>$29278</td>\n",
       "      <td>$59696</td>\n",
       "      <td>$127613</td>\n",
       "      <td>787</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1746</td>\n",
       "      <td>53</td>\n",
       "      <td>68</td>\n",
       "      <td>1966</td>\n",
       "      <td>12</td>\n",
       "      <td>Female</td>\n",
       "      <td>3606 Federal Boulevard</td>\n",
       "      <td>40.76</td>\n",
       "      <td>-73.74</td>\n",
       "      <td>$37891</td>\n",
       "      <td>$77254</td>\n",
       "      <td>$191349</td>\n",
       "      <td>701</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1718</td>\n",
       "      <td>81</td>\n",
       "      <td>67</td>\n",
       "      <td>1938</td>\n",
       "      <td>11</td>\n",
       "      <td>Female</td>\n",
       "      <td>766 Third Drive</td>\n",
       "      <td>34.02</td>\n",
       "      <td>-117.89</td>\n",
       "      <td>$22681</td>\n",
       "      <td>$33483</td>\n",
       "      <td>$196</td>\n",
       "      <td>698</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>708</td>\n",
       "      <td>63</td>\n",
       "      <td>63</td>\n",
       "      <td>1957</td>\n",
       "      <td>1</td>\n",
       "      <td>Female</td>\n",
       "      <td>3 Madison Street</td>\n",
       "      <td>40.71</td>\n",
       "      <td>-73.99</td>\n",
       "      <td>$163145</td>\n",
       "      <td>$249925</td>\n",
       "      <td>$202328</td>\n",
       "      <td>722</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1164</td>\n",
       "      <td>43</td>\n",
       "      <td>70</td>\n",
       "      <td>1976</td>\n",
       "      <td>9</td>\n",
       "      <td>Male</td>\n",
       "      <td>9620 Valley Stream Drive</td>\n",
       "      <td>37.76</td>\n",
       "      <td>-122.44</td>\n",
       "      <td>$53797</td>\n",
       "      <td>$109687</td>\n",
       "      <td>$183855</td>\n",
       "      <td>675</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  current_age  retirement_age  birth_year  birth_month  gender  \\\n",
       "0   825           53              66        1966           11  Female   \n",
       "1  1746           53              68        1966           12  Female   \n",
       "2  1718           81              67        1938           11  Female   \n",
       "3   708           63              63        1957            1  Female   \n",
       "4  1164           43              70        1976            9    Male   \n",
       "\n",
       "                    address  latitude  longitude per_capita_income  \\\n",
       "0             462 Rose Lane     34.15    -117.76            $29278   \n",
       "1    3606 Federal Boulevard     40.76     -73.74            $37891   \n",
       "2           766 Third Drive     34.02    -117.89            $22681   \n",
       "3          3 Madison Street     40.71     -73.99           $163145   \n",
       "4  9620 Valley Stream Drive     37.76    -122.44            $53797   \n",
       "\n",
       "  yearly_income total_debt  credit_score  num_credit_cards  \n",
       "0        $59696    $127613           787                 5  \n",
       "1        $77254    $191349           701                 5  \n",
       "2        $33483       $196           698                 5  \n",
       "3       $249925    $202328           722                 4  \n",
       "4       $109687    $183855           675                 1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load users data\n",
    "users = pd.read_csv(r'/Users/teslim/Large_data_set/users_data.csv')\n",
    "users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2000 entries, 0 to 1999\n",
      "Data columns (total 14 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   id                 2000 non-null   int64  \n",
      " 1   current_age        2000 non-null   int64  \n",
      " 2   retirement_age     2000 non-null   int64  \n",
      " 3   birth_year         2000 non-null   int64  \n",
      " 4   birth_month        2000 non-null   int64  \n",
      " 5   gender             2000 non-null   object \n",
      " 6   address            2000 non-null   object \n",
      " 7   latitude           2000 non-null   float64\n",
      " 8   longitude          2000 non-null   float64\n",
      " 9   per_capita_income  2000 non-null   object \n",
      " 10  yearly_income      2000 non-null   object \n",
      " 11  total_debt         2000 non-null   object \n",
      " 12  credit_score       2000 non-null   int64  \n",
      " 13  num_credit_cards   2000 non-null   int64  \n",
      "dtypes: float64(2), int64(7), object(5)\n",
      "memory usage: 218.9+ KB\n"
     ]
    }
   ],
   "source": [
    "# Check the data types of the columns\n",
    "users.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                   0\n",
       "current_age          0\n",
       "retirement_age       0\n",
       "birth_year           0\n",
       "birth_month          0\n",
       "gender               0\n",
       "address              0\n",
       "latitude             0\n",
       "longitude            0\n",
       "per_capita_income    0\n",
       "yearly_income        0\n",
       "total_debt           0\n",
       "credit_score         0\n",
       "num_credit_cards     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for missing values\n",
    "users.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is crucial to convert the columns to their appropriate data types based on the nature of the data. This step ensures accurate analysis and processing of the information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_users_data(data):\n",
    "    data['per_capita_income'] = data['per_capita_income'].str.replace(\"$\", \"\").str.replace(\",\", \"\").astype(float)\n",
    "    data['yearly_income'] = data['yearly_income'].str.replace(\"$\", \"\").str.replace(\",\", \"\").astype(float)\n",
    "    data['total_debt'] = data['total_debt'].str.replace(\"$\", \"\").str.replace(\",\", \"\").astype(float)\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Clean users data\n",
    "users_data = clean_users_data(users)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2000 entries, 0 to 1999\n",
      "Data columns (total 14 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   id                 2000 non-null   int64  \n",
      " 1   current_age        2000 non-null   int64  \n",
      " 2   retirement_age     2000 non-null   int64  \n",
      " 3   birth_year         2000 non-null   int64  \n",
      " 4   birth_month        2000 non-null   int64  \n",
      " 5   gender             2000 non-null   object \n",
      " 6   address            2000 non-null   object \n",
      " 7   latitude           2000 non-null   float64\n",
      " 8   longitude          2000 non-null   float64\n",
      " 9   per_capita_income  2000 non-null   float64\n",
      " 10  yearly_income      2000 non-null   float64\n",
      " 11  total_debt         2000 non-null   float64\n",
      " 12  credit_score       2000 non-null   int64  \n",
      " 13  num_credit_cards   2000 non-null   int64  \n",
      "dtypes: float64(5), int64(7), object(2)\n",
      "memory usage: 218.9+ KB\n"
     ]
    }
   ],
   "source": [
    "# check the data types after cleaning\n",
    "users_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading dataset: card_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "client_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "card_brand",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "card_type",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "card_number",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "expires",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "cvv",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "has_chip",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "num_cards_issued",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "credit_limit",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "acct_open_date",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "year_pin_last_changed",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "card_on_dark_web",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "67bb2279-c814-439c-8e4a-ff54bc0c3d01",
       "rows": [
        [
         "0",
         "4524",
         "825",
         "Visa",
         "Debit",
         "4344676511950444",
         "12/2022",
         "623",
         "YES",
         "2",
         "$24295",
         "09/2002",
         "2008",
         "No"
        ],
        [
         "1",
         "2731",
         "825",
         "Visa",
         "Debit",
         "4956965974959986",
         "12/2020",
         "393",
         "YES",
         "2",
         "$21968",
         "04/2014",
         "2014",
         "No"
        ],
        [
         "2",
         "3701",
         "825",
         "Visa",
         "Debit",
         "4582313478255491",
         "02/2024",
         "719",
         "YES",
         "2",
         "$46414",
         "07/2003",
         "2004",
         "No"
        ],
        [
         "3",
         "42",
         "825",
         "Visa",
         "Credit",
         "4879494103069057",
         "08/2024",
         "693",
         "NO",
         "1",
         "$12400",
         "01/2003",
         "2012",
         "No"
        ],
        [
         "4",
         "4659",
         "825",
         "Mastercard",
         "Debit (Prepaid)",
         "5722874738736011",
         "03/2009",
         "75",
         "YES",
         "1",
         "$28",
         "09/2008",
         "2009",
         "No"
        ]
       ],
       "shape": {
        "columns": 13,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>client_id</th>\n",
       "      <th>card_brand</th>\n",
       "      <th>card_type</th>\n",
       "      <th>card_number</th>\n",
       "      <th>expires</th>\n",
       "      <th>cvv</th>\n",
       "      <th>has_chip</th>\n",
       "      <th>num_cards_issued</th>\n",
       "      <th>credit_limit</th>\n",
       "      <th>acct_open_date</th>\n",
       "      <th>year_pin_last_changed</th>\n",
       "      <th>card_on_dark_web</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4524</td>\n",
       "      <td>825</td>\n",
       "      <td>Visa</td>\n",
       "      <td>Debit</td>\n",
       "      <td>4344676511950444</td>\n",
       "      <td>12/2022</td>\n",
       "      <td>623</td>\n",
       "      <td>YES</td>\n",
       "      <td>2</td>\n",
       "      <td>$24295</td>\n",
       "      <td>09/2002</td>\n",
       "      <td>2008</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2731</td>\n",
       "      <td>825</td>\n",
       "      <td>Visa</td>\n",
       "      <td>Debit</td>\n",
       "      <td>4956965974959986</td>\n",
       "      <td>12/2020</td>\n",
       "      <td>393</td>\n",
       "      <td>YES</td>\n",
       "      <td>2</td>\n",
       "      <td>$21968</td>\n",
       "      <td>04/2014</td>\n",
       "      <td>2014</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3701</td>\n",
       "      <td>825</td>\n",
       "      <td>Visa</td>\n",
       "      <td>Debit</td>\n",
       "      <td>4582313478255491</td>\n",
       "      <td>02/2024</td>\n",
       "      <td>719</td>\n",
       "      <td>YES</td>\n",
       "      <td>2</td>\n",
       "      <td>$46414</td>\n",
       "      <td>07/2003</td>\n",
       "      <td>2004</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42</td>\n",
       "      <td>825</td>\n",
       "      <td>Visa</td>\n",
       "      <td>Credit</td>\n",
       "      <td>4879494103069057</td>\n",
       "      <td>08/2024</td>\n",
       "      <td>693</td>\n",
       "      <td>NO</td>\n",
       "      <td>1</td>\n",
       "      <td>$12400</td>\n",
       "      <td>01/2003</td>\n",
       "      <td>2012</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4659</td>\n",
       "      <td>825</td>\n",
       "      <td>Mastercard</td>\n",
       "      <td>Debit (Prepaid)</td>\n",
       "      <td>5722874738736011</td>\n",
       "      <td>03/2009</td>\n",
       "      <td>75</td>\n",
       "      <td>YES</td>\n",
       "      <td>1</td>\n",
       "      <td>$28</td>\n",
       "      <td>09/2008</td>\n",
       "      <td>2009</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  client_id  card_brand        card_type       card_number  expires  \\\n",
       "0  4524        825        Visa            Debit  4344676511950444  12/2022   \n",
       "1  2731        825        Visa            Debit  4956965974959986  12/2020   \n",
       "2  3701        825        Visa            Debit  4582313478255491  02/2024   \n",
       "3    42        825        Visa           Credit  4879494103069057  08/2024   \n",
       "4  4659        825  Mastercard  Debit (Prepaid)  5722874738736011  03/2009   \n",
       "\n",
       "   cvv has_chip  num_cards_issued credit_limit acct_open_date  \\\n",
       "0  623      YES                 2       $24295        09/2002   \n",
       "1  393      YES                 2       $21968        04/2014   \n",
       "2  719      YES                 2       $46414        07/2003   \n",
       "3  693       NO                 1       $12400        01/2003   \n",
       "4   75      YES                 1          $28        09/2008   \n",
       "\n",
       "   year_pin_last_changed card_on_dark_web  \n",
       "0                   2008               No  \n",
       "1                   2014               No  \n",
       "2                   2004               No  \n",
       "3                   2012               No  \n",
       "4                   2009               No  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load card data\n",
    "cards = pd.read_csv(r'/Users/teslim/Large_data_set/cards_data.csv')\n",
    "cards.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6146 entries, 0 to 6145\n",
      "Data columns (total 13 columns):\n",
      " #   Column                 Non-Null Count  Dtype \n",
      "---  ------                 --------------  ----- \n",
      " 0   id                     6146 non-null   int64 \n",
      " 1   client_id              6146 non-null   int64 \n",
      " 2   card_brand             6146 non-null   object\n",
      " 3   card_type              6146 non-null   object\n",
      " 4   card_number            6146 non-null   int64 \n",
      " 5   expires                6146 non-null   object\n",
      " 6   cvv                    6146 non-null   int64 \n",
      " 7   has_chip               6146 non-null   object\n",
      " 8   num_cards_issued       6146 non-null   int64 \n",
      " 9   credit_limit           6146 non-null   object\n",
      " 10  acct_open_date         6146 non-null   object\n",
      " 11  year_pin_last_changed  6146 non-null   int64 \n",
      " 12  card_on_dark_web       6146 non-null   object\n",
      "dtypes: int64(6), object(7)\n",
      "memory usage: 624.3+ KB\n"
     ]
    }
   ],
   "source": [
    "# check the data types\n",
    "cards.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                       0\n",
       "client_id                0\n",
       "card_brand               0\n",
       "card_type                0\n",
       "card_number              0\n",
       "expires                  0\n",
       "cvv                      0\n",
       "has_chip                 0\n",
       "num_cards_issued         0\n",
       "credit_limit             0\n",
       "acct_open_date           0\n",
       "year_pin_last_changed    0\n",
       "card_on_dark_web         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for missing values\n",
    "cards.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting columns to appropriate data types for accurate analysis and processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def clean_cards_data(data):\n",
    "    \"\"\"\n",
    "    Cleans the cards data:\n",
    "    1. Converts 'expires' and 'acct_open_date' to datetime.\n",
    "    2. Cleans and converts 'credit_limit' to float.\n",
    "    3. Converts 'year_pin_last_changed' to integer (since it contains only years).\n",
    "    4. Handles missing values.\n",
    "    \"\"\"\n",
    "    # Convert 'expires' to datetime (assuming format is 'MM/YYYY')\n",
    "    data['expires'] = pd.to_datetime(data['expires'], format='%m/%Y', errors='coerce')\n",
    "    \n",
    "\n",
    "    data['credit_limit'] = (data['credit_limit'].str.replace(r'[$,]', '', regex=True).astype(float))\n",
    "    \n",
    "    # Convert 'acct_open_date' to datetime (assuming format is 'MM/DD/YYYY')\n",
    "    data['acct_open_date'] = pd.to_datetime(data['acct_open_date'], format='%m/%d/%Y', errors='coerce')\n",
    "    \n",
    "    # Convert 'year_pin_last_changed' to integer (since it contains only years)\n",
    "    data['year_pin_last_changed'] = pd.to_numeric(data['year_pin_last_changed'], errors='coerce').astype('Int64')  # Use 'Int64' for nullable integer type\n",
    "    \n",
    "    # Handle missing values (optional, depending on your use case)\n",
    "    data['expires'] = data['expires'].fillna(pd.NaT)  # Fill missing datetime with NaT\n",
    "    data['credit_limit'] = data['credit_limit'].fillna(0.0)  # Fill missing credit limits with 0.0\n",
    "    data['acct_open_date'] = data['acct_open_date'].fillna(pd.NaT)  # Fill missing datetime with NaT\n",
    "    data['year_pin_last_changed'] = data['year_pin_last_changed'].fillna(0)  # Fill missing years with 0\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Clean cards data\n",
    "cards_data = clean_cards_data(cards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6146 entries, 0 to 6145\n",
      "Data columns (total 13 columns):\n",
      " #   Column                 Non-Null Count  Dtype         \n",
      "---  ------                 --------------  -----         \n",
      " 0   id                     6146 non-null   int64         \n",
      " 1   client_id              6146 non-null   int64         \n",
      " 2   card_brand             6146 non-null   object        \n",
      " 3   card_type              6146 non-null   object        \n",
      " 4   card_number            6146 non-null   int64         \n",
      " 5   expires                6146 non-null   datetime64[ns]\n",
      " 6   cvv                    6146 non-null   int64         \n",
      " 7   has_chip               6146 non-null   object        \n",
      " 8   num_cards_issued       6146 non-null   int64         \n",
      " 9   credit_limit           6146 non-null   float64       \n",
      " 10  acct_open_date         0 non-null      datetime64[ns]\n",
      " 11  year_pin_last_changed  6146 non-null   Int64         \n",
      " 12  card_on_dark_web       6146 non-null   object        \n",
      "dtypes: Int64(1), datetime64[ns](2), float64(1), int64(5), object(4)\n",
      "memory usage: 630.3+ KB\n"
     ]
    }
   ],
   "source": [
    "cards_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading dataset: mcc_codes_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "0",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "fca88734-f77a-430d-ac1e-b8c7eaca3d78",
       "rows": [
        [
         "5812",
         "Eating Places and Restaurants"
        ],
        [
         "5541",
         "Service Stations"
        ],
        [
         "7996",
         "Amusement Parks, Carnivals, Circuses"
        ],
        [
         "5411",
         "Grocery Stores, Supermarkets"
        ],
        [
         "4784",
         "Tolls and Bridge Fees"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5812</th>\n",
       "      <td>Eating Places and Restaurants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5541</th>\n",
       "      <td>Service Stations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7996</th>\n",
       "      <td>Amusement Parks, Carnivals, Circuses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5411</th>\n",
       "      <td>Grocery Stores, Supermarkets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4784</th>\n",
       "      <td>Tolls and Bridge Fees</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         0\n",
       "5812         Eating Places and Restaurants\n",
       "5541                      Service Stations\n",
       "7996  Amusement Parks, Carnivals, Circuses\n",
       "5411          Grocery Stores, Supermarkets\n",
       "4784                 Tolls and Bridge Fees"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load mcc codes data\n",
    "mcc_codes_data = pd.read_json(\"/Users/teslim/Large_data_set/mcc_codes.json\", orient='index')\n",
    "mcc_codes_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 109 entries, 5812 to 5733\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   0       109 non-null    object\n",
      "dtypes: object(1)\n",
      "memory usage: 1.7+ KB\n"
     ]
    }
   ],
   "source": [
    "mcc_codes_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for missing values\n",
    "mcc_codes_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load dataset: Transaction_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "date",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "client_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "card_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "amount",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "use_chip",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "merchant_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "merchant_city",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "merchant_state",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "zip",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "mcc",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "errors",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "32253ce1-9390-4a56-9a05-de9853541d70",
       "rows": [
        [
         "0",
         "7475327",
         "2010-01-01 00:01:00",
         "1556",
         "2972",
         "$-77.00",
         "Swipe Transaction",
         "59935",
         "Beulah",
         "ND",
         "58523.0",
         "5499",
         null
        ],
        [
         "1",
         "7475328",
         "2010-01-01 00:02:00",
         "561",
         "4575",
         "$14.57",
         "Swipe Transaction",
         "67570",
         "Bettendorf",
         "IA",
         "52722.0",
         "5311",
         null
        ],
        [
         "2",
         "7475329",
         "2010-01-01 00:02:00",
         "1129",
         "102",
         "$80.00",
         "Swipe Transaction",
         "27092",
         "Vista",
         "CA",
         "92084.0",
         "4829",
         null
        ],
        [
         "3",
         "7475331",
         "2010-01-01 00:05:00",
         "430",
         "2860",
         "$200.00",
         "Swipe Transaction",
         "27092",
         "Crown Point",
         "IN",
         "46307.0",
         "4829",
         null
        ],
        [
         "4",
         "7475332",
         "2010-01-01 00:06:00",
         "848",
         "3915",
         "$46.41",
         "Swipe Transaction",
         "13051",
         "Harwood",
         "MD",
         "20776.0",
         "5813",
         null
        ]
       ],
       "shape": {
        "columns": 12,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>client_id</th>\n",
       "      <th>card_id</th>\n",
       "      <th>amount</th>\n",
       "      <th>use_chip</th>\n",
       "      <th>merchant_id</th>\n",
       "      <th>merchant_city</th>\n",
       "      <th>merchant_state</th>\n",
       "      <th>zip</th>\n",
       "      <th>mcc</th>\n",
       "      <th>errors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7475327</td>\n",
       "      <td>2010-01-01 00:01:00</td>\n",
       "      <td>1556</td>\n",
       "      <td>2972</td>\n",
       "      <td>$-77.00</td>\n",
       "      <td>Swipe Transaction</td>\n",
       "      <td>59935</td>\n",
       "      <td>Beulah</td>\n",
       "      <td>ND</td>\n",
       "      <td>58523.0</td>\n",
       "      <td>5499</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7475328</td>\n",
       "      <td>2010-01-01 00:02:00</td>\n",
       "      <td>561</td>\n",
       "      <td>4575</td>\n",
       "      <td>$14.57</td>\n",
       "      <td>Swipe Transaction</td>\n",
       "      <td>67570</td>\n",
       "      <td>Bettendorf</td>\n",
       "      <td>IA</td>\n",
       "      <td>52722.0</td>\n",
       "      <td>5311</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7475329</td>\n",
       "      <td>2010-01-01 00:02:00</td>\n",
       "      <td>1129</td>\n",
       "      <td>102</td>\n",
       "      <td>$80.00</td>\n",
       "      <td>Swipe Transaction</td>\n",
       "      <td>27092</td>\n",
       "      <td>Vista</td>\n",
       "      <td>CA</td>\n",
       "      <td>92084.0</td>\n",
       "      <td>4829</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7475331</td>\n",
       "      <td>2010-01-01 00:05:00</td>\n",
       "      <td>430</td>\n",
       "      <td>2860</td>\n",
       "      <td>$200.00</td>\n",
       "      <td>Swipe Transaction</td>\n",
       "      <td>27092</td>\n",
       "      <td>Crown Point</td>\n",
       "      <td>IN</td>\n",
       "      <td>46307.0</td>\n",
       "      <td>4829</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7475332</td>\n",
       "      <td>2010-01-01 00:06:00</td>\n",
       "      <td>848</td>\n",
       "      <td>3915</td>\n",
       "      <td>$46.41</td>\n",
       "      <td>Swipe Transaction</td>\n",
       "      <td>13051</td>\n",
       "      <td>Harwood</td>\n",
       "      <td>MD</td>\n",
       "      <td>20776.0</td>\n",
       "      <td>5813</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                date  client_id  card_id   amount  \\\n",
       "0  7475327 2010-01-01 00:01:00       1556     2972  $-77.00   \n",
       "1  7475328 2010-01-01 00:02:00        561     4575   $14.57   \n",
       "2  7475329 2010-01-01 00:02:00       1129      102   $80.00   \n",
       "3  7475331 2010-01-01 00:05:00        430     2860  $200.00   \n",
       "4  7475332 2010-01-01 00:06:00        848     3915   $46.41   \n",
       "\n",
       "            use_chip  merchant_id merchant_city merchant_state      zip   mcc  \\\n",
       "0  Swipe Transaction        59935        Beulah             ND  58523.0  5499   \n",
       "1  Swipe Transaction        67570    Bettendorf             IA  52722.0  5311   \n",
       "2  Swipe Transaction        27092         Vista             CA  92084.0  4829   \n",
       "3  Swipe Transaction        27092   Crown Point             IN  46307.0  4829   \n",
       "4  Swipe Transaction        13051       Harwood             MD  20776.0  5813   \n",
       "\n",
       "  errors  \n",
       "0    NaN  \n",
       "1    NaN  \n",
       "2    NaN  \n",
       "3    NaN  \n",
       "4    NaN  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load transactions data\n",
    "transactions = pd.read_csv(r'/Users/teslim/Large_data_set/transactions_data.csv', parse_dates=['date'])\n",
    "transactions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13305915 entries, 0 to 13305914\n",
      "Data columns (total 12 columns):\n",
      " #   Column          Dtype         \n",
      "---  ------          -----         \n",
      " 0   id              int64         \n",
      " 1   date            datetime64[ns]\n",
      " 2   client_id       int64         \n",
      " 3   card_id         int64         \n",
      " 4   amount          object        \n",
      " 5   use_chip        object        \n",
      " 6   merchant_id     int64         \n",
      " 7   merchant_city   object        \n",
      " 8   merchant_state  object        \n",
      " 9   zip             float64       \n",
      " 10  mcc             int64         \n",
      " 11  errors          object        \n",
      "dtypes: datetime64[ns](1), float64(1), int64(5), object(5)\n",
      "memory usage: 1.2+ GB\n"
     ]
    }
   ],
   "source": [
    "# check the data types\n",
    "transactions.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                       0\n",
       "date                     0\n",
       "client_id                0\n",
       "card_id                  0\n",
       "amount                   0\n",
       "use_chip                 0\n",
       "merchant_id              0\n",
       "merchant_city            0\n",
       "merchant_state     1563700\n",
       "zip                1652706\n",
       "mcc                      0\n",
       "errors            13094522\n",
       "dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for missing values\n",
    "transactions.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset contains transaction details such as transaction_id, transaction_date, user_id, card_id, merchant_id, mcc_code, amount, and other relevant information, and it is important that dollar amounts are stored as numeric values for financial analysis, thus, this will be converted to the appropriate data type using the function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean transactions data\n",
    "def clean_transactions_data(transactions_df):\n",
    "\t\"\"\"\n",
    "\tCleans the transactions data using vectorized operations:\n",
    "\t1. Removes dollar signs, commas, and parentheses from the `amount` column and converts it to float.\n",
    "\t2. Converts the `date` column to a datetime object.\n",
    "\t3. Handles missing values in `merchant_state`, `zip`, and `errors` columns.\n",
    "\t4. Returns a cleaned DataFrame.\n",
    "\t\"\"\"\n",
    "\t# Clean the `amount` column\n",
    "\ttransactions_df['amount'] = (\n",
    "\t\ttransactions_df['amount']\n",
    "\t\t.str.replace('$', '', regex=False)  # Remove dollar signs\n",
    "\t\t.str.replace(',', '', regex=False)  # Remove commas\n",
    "\t\t.str.replace('(', '-', regex=False)  # Replace opening parenthesis with negative sign\n",
    "\t\t.str.replace(')', '', regex=False)  # Remove closing parenthesis\n",
    "\t\t.astype(float)  # Convert to float\n",
    "\t)\n",
    "\t\n",
    "\t# Convert the `date` column to datetime\n",
    "\ttransactions_df['date'] = pd.to_datetime(transactions_df['date'])\n",
    "\t\n",
    "\t# Handle missing values in `merchant_state`, `zip`, and `errors`\n",
    "\ttransactions_df['merchant_state'] = transactions_df['merchant_state'].fillna('Unknown')\n",
    "\ttransactions_df['zip'] = transactions_df['zip'].fillna('Unknown')\n",
    "\ttransactions_df['errors'] = transactions_df['errors'].fillna('No Errors')\n",
    "\t\n",
    "\t# Convert specific columns to integers\n",
    "\tint_columns = ['id', 'client_id', 'card_id', 'merchant_id', 'mcc']\n",
    "\ttransactions_df[int_columns] = transactions_df[int_columns].astype(int)\n",
    "\t\n",
    "\t# Rename columns to match the database schema (optional)\n",
    "\ttransactions_df = transactions_df.rename(columns={\n",
    "\t\t'id': 'transaction_id',\n",
    "\t\t'client_id': 'user_id',\n",
    "\t\t'date': 'transaction_date',\n",
    "\t\t'mcc': 'mcc_code'\n",
    "\t})\n",
    "\t\n",
    "\treturn transactions_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean transactions data\n",
    "transactions_data = clean_transactions_data(transactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13305915 entries, 0 to 13305914\n",
      "Data columns (total 12 columns):\n",
      " #   Column            Dtype         \n",
      "---  ------            -----         \n",
      " 0   transaction_id    int64         \n",
      " 1   transaction_date  datetime64[ns]\n",
      " 2   user_id           int64         \n",
      " 3   card_id           int64         \n",
      " 4   amount            float64       \n",
      " 5   use_chip          object        \n",
      " 6   merchant_id       int64         \n",
      " 7   merchant_city     object        \n",
      " 8   merchant_state    object        \n",
      " 9   zip               object        \n",
      " 10  mcc_code          int64         \n",
      " 11  errors            object        \n",
      "dtypes: datetime64[ns](1), float64(1), int64(5), object(5)\n",
      "memory usage: 1.2+ GB\n"
     ]
    }
   ],
   "source": [
    "transactions_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading dataset: Train_fraud_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "target",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "89d48118-21b9-47b0-b803-9c9573a50f8f",
       "rows": [
        [
         "10649266",
         "No"
        ],
        [
         "23410063",
         "No"
        ],
        [
         "9316588",
         "No"
        ],
        [
         "12478022",
         "No"
        ],
        [
         "9558530",
         "No"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10649266</th>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23410063</th>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9316588</th>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12478022</th>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9558530</th>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         target\n",
       "10649266     No\n",
       "23410063     No\n",
       "9316588      No\n",
       "12478022     No\n",
       "9558530      No"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load fraud labels data\n",
    "fraud_labels_data = pd.read_json(r'/Users/teslim/Large_data_set/train_fraud_labels.json')\n",
    "fraud_labels_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 8914963 entries, 10649266 to 15151926\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Dtype \n",
      "---  ------  ----- \n",
      " 0   target  object\n",
      "dtypes: object(1)\n",
      "memory usage: 136.0+ MB\n"
     ]
    }
   ],
   "source": [
    "fraud_labels_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for missing values\n",
    "fraud_labels_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQL Database Initialization\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is the Database Initialization, which involves creating a new database, establishing connections, and loading the dataset into the database. This process is crucial for subsequent data analysis, forecasting, and visualization tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MySQL credentials loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import mysql.connector\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Retrieve MySQL credentials from environment variables\n",
    "MYSQL_USER = os.getenv(\"MYSQL_USERNAME\")\n",
    "MYSQL_PASSWORD = os.getenv(\"MYSQL_PASSWORD\")\n",
    "MYSQL_HOST = os.getenv(\"MYSQL_HOST\")\n",
    "\n",
    "# Validate credentials\n",
    "if not MYSQL_USER or not MYSQL_PASSWORD or not MYSQL_HOST:\n",
    "    raise ValueError(\"Missing MySQL credentials. Please check your .env file.\")\n",
    "else:\n",
    "    print(\"MySQL credentials loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to SQL Database\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After initializing the database, the next step is to connect to the SQL database using Python. This connection is essential for querying the database, extracting data, and performing various data analysis tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database 'financial_transactions_db' created successfully and connected.\n"
     ]
    }
   ],
   "source": [
    "# Database connection function\n",
    "def connect_to_db():\n",
    "    return mysql.connector.connect(\n",
    "        host=MYSQL_HOST,\n",
    "        user=MYSQL_USER,\n",
    "        password=MYSQL_PASSWORD\n",
    "    )\n",
    "\n",
    "# Databse creation function\n",
    "def create_database():\n",
    "    conn = connect_to_db()\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\"CREATE DATABASE IF NOT EXISTS financial_transactions_db\")\n",
    "    print(\"Database 'financial_transactions_db' created successfully and connected.\")\n",
    "    conn.close()\n",
    "\n",
    "# Connect to the database function\n",
    "def connect_to_db_with_db():\n",
    "    return mysql.connector.connect(\n",
    "        host=MYSQL_HOST,\n",
    "        user=MYSQL_USER,\n",
    "        password=MYSQL_PASSWORD,\n",
    "        database=\"financial_transactions_db\"\n",
    "    )\n",
    "\n",
    "# Call the functions\n",
    "create_database()\n",
    "db = connect_to_db_with_db()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Tables\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Followinng the set up of the  database, the next step is create the tables in the database, and insert data. The tables will be created based on the schema and relationships defined earlier.\n",
    "\n",
    "The tables will be created:\n",
    "- users\n",
    "- cards\n",
    "- mcc_codes\n",
    "- transactions\n",
    "- fraud_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_users_table():\n",
    "    \"\"\"\n",
    "    Creates the 'users' table in the database with the correct schema.\n",
    "    \"\"\"\n",
    "    conn = connect_to_db_with_db()\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS users (\n",
    "        user_id BIGINT UNSIGNED PRIMARY KEY, -- Ensures consistency across foreign keys\n",
    "        current_age INT,\n",
    "        retirement_age INT,\n",
    "        birth_year INT,\n",
    "        birth_month INT,\n",
    "        gender VARCHAR(10),\n",
    "        address VARCHAR(255),\n",
    "        latitude DOUBLE PRECISION,         \n",
    "        longitude DOUBLE PRECISION,        \n",
    "        per_capita_income DOUBLE PRECISION, \n",
    "        yearly_income DOUBLE PRECISION,    \n",
    "        total_debt DOUBLE PRECISION,       \n",
    "        credit_score INT,\n",
    "        num_credit_cards INT\n",
    "    );\n",
    "    \"\"\")\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "    print(\"Table 'users' created successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cards_table():\n",
    "    \"\"\"\n",
    "    Creates the 'cards' table in the database with the correct schema.\n",
    "    \"\"\"\n",
    "    conn = connect_to_db_with_db()\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS cards (\n",
    "        card_id BIGINT UNSIGNED PRIMARY KEY,\n",
    "        user_id BIGINT UNSIGNED NOT NULL, \n",
    "        card_brand VARCHAR(50),\n",
    "        card_type VARCHAR(50),\n",
    "        card_number BIGINT,\n",
    "        expires DATE,\n",
    "        cvv INT,\n",
    "        has_chip VARCHAR(10),\n",
    "        num_cards_issued INT,\n",
    "        credit_limit DOUBLE PRECISION, \n",
    "        acct_open_date DATE,\n",
    "        year_pin_last_changed INT,\n",
    "        card_on_dark_web VARCHAR(10),\n",
    "        FOREIGN KEY (user_id) REFERENCES users(user_id) ON DELETE CASCADE\n",
    "    );\n",
    "    \"\"\")\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "    print(\"Table 'cards' created successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mcc_codes_table():\n",
    "    \"\"\"\n",
    "    Creates the 'mcc_codes' table in the database with merchant category codes.\n",
    "    \"\"\"\n",
    "    conn = connect_to_db_with_db()\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS mcc_codes (\n",
    "        mcc_code BIGINT UNSIGNED PRIMARY KEY,\n",
    "        category_description VARCHAR(255)\n",
    "    );\n",
    "    \"\"\")\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "    print(\"Table 'mcc_codes' created successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_transactions_table():\n",
    "    \"\"\"\n",
    "    Creates the 'transactions' table in the database with the correct schema.\n",
    "    \"\"\"\n",
    "    conn = connect_to_db_with_db()\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS transactions (\n",
    "        transaction_id BIGINT UNSIGNED PRIMARY KEY,  \n",
    "        transaction_date DATE,  \n",
    "        user_id BIGINT UNSIGNED NOT NULL,  \n",
    "        card_id BIGINT UNSIGNED NOT NULL,  \n",
    "        amount DOUBLE PRECISION,  \n",
    "        use_chip VARCHAR(50),  \n",
    "        merchant_id BIGINT UNSIGNED,  \n",
    "        merchant_city TEXT,  \n",
    "        merchant_state VARCHAR(50),  \n",
    "        zip VARCHAR(20),  \n",
    "        mcc_code BIGINT UNSIGNED,  \n",
    "        errors TEXT,  \n",
    "        FOREIGN KEY (user_id) REFERENCES users(user_id) ON DELETE CASCADE,  \n",
    "        FOREIGN KEY (card_id) REFERENCES cards(card_id) ON DELETE CASCADE,  \n",
    "        FOREIGN KEY (mcc_code) REFERENCES mcc_codes(mcc_code) ON DELETE SET NULL\n",
    "    );\n",
    "    \"\"\")\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "    print(\"Table 'transactions' created successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_fraud_table():\n",
    "    \"\"\"\n",
    "    Creates the 'fraud_labels' table in the database.\n",
    "    \"\"\"\n",
    "    conn = connect_to_db_with_db()\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS fraud_labels (\n",
    "        transaction_id BIGINT UNSIGNED PRIMARY KEY,  \n",
    "        is_fraud BOOLEAN,  \n",
    "        FOREIGN KEY (transaction_id) REFERENCES transactions(transaction_id) ON DELETE CASCADE\n",
    "    );\n",
    "    \"\"\")\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "    print(\"Table 'fraud_labels' created successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 'users' created successfully.\n",
      "Table 'cards' created successfully.\n",
      "Table 'mcc_codes' created successfully.\n",
      "Table 'transactions' created successfully.\n",
      "Table 'fraud_labels' created successfully.\n"
     ]
    }
   ],
   "source": [
    "# Create tables\n",
    "create_users_table()\n",
    "create_cards_table()\n",
    "create_mcc_codes_table()\n",
    "create_transactions_table()\n",
    "create_fraud_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('cards',)\n",
      "('fraud_labels',)\n",
      "('mcc_codes',)\n",
      "('transactions',)\n",
      "('users',)\n"
     ]
    }
   ],
   "source": [
    "# Show tables in the financial_transactions_db database\n",
    "cursor = db.cursor()\n",
    "cursor.execute(\"SHOW TABLES IN financial_transactions_db\")\n",
    "tables = cursor.fetchall()\n",
    "for table in tables:\n",
    "\tprint(table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After creating the tables, the next step is to establish relationships between them to ensure data integrity and consistency. After that, we will proceed to the next section of inspecting the data into the tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insert Data into: User Table\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2000 entries, 0 to 1999\n",
      "Data columns (total 14 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   id                 2000 non-null   int64  \n",
      " 1   current_age        2000 non-null   int64  \n",
      " 2   retirement_age     2000 non-null   int64  \n",
      " 3   birth_year         2000 non-null   int64  \n",
      " 4   birth_month        2000 non-null   int64  \n",
      " 5   gender             2000 non-null   object \n",
      " 6   address            2000 non-null   object \n",
      " 7   latitude           2000 non-null   float64\n",
      " 8   longitude          2000 non-null   float64\n",
      " 9   per_capita_income  2000 non-null   float64\n",
      " 10  yearly_income      2000 non-null   float64\n",
      " 11  total_debt         2000 non-null   float64\n",
      " 12  credit_score       2000 non-null   int64  \n",
      " 13  num_credit_cards   2000 non-null   int64  \n",
      "dtypes: float64(5), int64(7), object(2)\n",
      "memory usage: 218.9+ KB\n"
     ]
    }
   ],
   "source": [
    "users_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Users data inserted successfully.\n"
     ]
    }
   ],
   "source": [
    "# Insert users data into the users table\n",
    "def insert_users_data(users_df):\n",
    "    \"\"\"\n",
    "    Inserts users' data from a DataFrame into the users table efficiently.\n",
    "    \"\"\"\n",
    "    # Ensure column alignment\n",
    "    users_df.rename(columns={'id': 'user_id'}, inplace=True)\n",
    "\n",
    "    # Connect to the database\n",
    "    conn = connect_to_db_with_db()\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Prepare SQL query\n",
    "    sql_query = \"\"\"\n",
    "        INSERT IGNORE INTO users (user_id, \n",
    "                           current_age, \n",
    "                           retirement_age, \n",
    "                           birth_year, \n",
    "                           birth_month, \n",
    "                           gender, \n",
    "                           address,\n",
    "                           latitude, \n",
    "                           longitude, \n",
    "                           per_capita_income, \n",
    "                           yearly_income, \n",
    "                           total_debt, \n",
    "                           credit_score, \n",
    "                           num_credit_cards)\n",
    "        VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert DataFrame to list of tuples (for executemany)\n",
    "    data_to_insert = [\n",
    "        (\n",
    "            int(row['user_id']), \n",
    "            int(row['current_age']), \n",
    "            int(row['retirement_age']),\n",
    "            int(row['birth_year']), \n",
    "            int(row['birth_month']), \n",
    "            row['gender'],\n",
    "            row['address'], \n",
    "            float(row['latitude']), \n",
    "            float(row['longitude']),\n",
    "            float(row['per_capita_income']), \n",
    "            float(row['yearly_income']), \n",
    "            float(row['total_debt']),\n",
    "            int(row['credit_score']), \n",
    "            int(row['num_credit_cards'])\n",
    "        )\n",
    "        for _, row in users_df.iterrows()\n",
    "    ]\n",
    "\n",
    "    # Execute batch insertion for better performance\n",
    "    cursor.executemany(sql_query, data_to_insert)\n",
    "\n",
    "    # Commit and close\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "\n",
    "    print(\"âœ… Users data inserted successfully.\")\n",
    "\n",
    "# Call the function\n",
    "insert_users_data(users_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Insert Data into: Cards Table\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6146 entries, 0 to 6145\n",
      "Data columns (total 13 columns):\n",
      " #   Column                 Non-Null Count  Dtype         \n",
      "---  ------                 --------------  -----         \n",
      " 0   id                     6146 non-null   int64         \n",
      " 1   client_id              6146 non-null   int64         \n",
      " 2   card_brand             6146 non-null   object        \n",
      " 3   card_type              6146 non-null   object        \n",
      " 4   card_number            6146 non-null   int64         \n",
      " 5   expires                6146 non-null   datetime64[ns]\n",
      " 6   cvv                    6146 non-null   int64         \n",
      " 7   has_chip               6146 non-null   object        \n",
      " 8   num_cards_issued       6146 non-null   int64         \n",
      " 9   credit_limit           6146 non-null   float64       \n",
      " 10  acct_open_date         0 non-null      datetime64[ns]\n",
      " 11  year_pin_last_changed  6146 non-null   Int64         \n",
      " 12  card_on_dark_web       6146 non-null   object        \n",
      "dtypes: Int64(1), datetime64[ns](2), float64(1), int64(5), object(4)\n",
      "memory usage: 630.3+ KB\n"
     ]
    }
   ],
   "source": [
    "cards_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Cards data inserted successfully.\n"
     ]
    }
   ],
   "source": [
    "# Insert cards data into the cards table\n",
    "def insert_cards_data(cards_df):\n",
    "    # Connect to the database\n",
    "    conn = connect_to_db_with_db()\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Iterate over each row in the DataFrame and insert it into the table\n",
    "    cards_df.rename(columns={'id': 'card_id'}, inplace=True)\n",
    "    \n",
    "    for index, row in cards_df.iterrows():\n",
    "        cursor.execute(\"\"\"\n",
    "            INSERT INTO cards (card_id, \n",
    "                               user_id, \n",
    "                               card_brand, \n",
    "                               card_type, \n",
    "                               card_number, \n",
    "                               expires, \n",
    "                               cvv, \n",
    "                               has_chip,\n",
    "                               num_cards_issued, \n",
    "                               credit_limit, \n",
    "                               acct_open_date, \n",
    "                               year_pin_last_changed, \n",
    "                               card_on_dark_web)\n",
    "            VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "        \"\"\", \n",
    "        (   int(row['card_id']), \n",
    "            int(row['client_id']), \n",
    "            row['card_brand'], \n",
    "            row['card_type'], \n",
    "            row['card_number'], \n",
    "            row['expires'], \n",
    "            row['cvv'], \n",
    "            row['has_chip'], \n",
    "            int(row['num_cards_issued']), \n",
    "            float(row['credit_limit']), \n",
    "            row['acct_open_date'], \n",
    "            int(row['year_pin_last_changed']), \n",
    "            row['card_on_dark_web']\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Commit the transaction\n",
    "    conn.commit()\n",
    "\n",
    "    # Close the connection\n",
    "    conn.close()\n",
    "\n",
    "    print(\"âœ… Cards data inserted successfully.\")\n",
    "\n",
    "# Call the function\n",
    "insert_cards_data(cards_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Insert Data into: MCC Codes Table\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 109 entries, 5812 to 5733\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   0       109 non-null    object\n",
      "dtypes: object(1)\n",
      "memory usage: 1.7+ KB\n"
     ]
    }
   ],
   "source": [
    "mcc_codes_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… MCC Codes data inserted successfully.\n"
     ]
    }
   ],
   "source": [
    "# Insert mcc codes data into the mcc_codes table\n",
    "def insert_mcc_codes_data(mcc_codes_df):\n",
    "    # Connect to the database\n",
    "    conn = connect_to_db_with_db()\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Iterate over each row in the DataFrame and insert it into the table\n",
    "    for index, row in mcc_codes_df.iterrows():\n",
    "        cursor.execute(\"\"\"\n",
    "            INSERT INTO mcc_codes (mcc_code, \n",
    "                                  category_description)\n",
    "            VALUES (%s, %s)\n",
    "        \"\"\", \n",
    "        (   index,  # Assuming `index` is the `mcc_code`\n",
    "            row[0]  # Assuming the first column is `category_description`\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Commit the transaction\n",
    "    conn.commit()\n",
    "\n",
    "    # Close the connection\n",
    "    conn.close()\n",
    "\n",
    "    print(\"âœ… MCC Codes data inserted successfully.\")\n",
    "\n",
    "# Call the function\n",
    "insert_mcc_codes_data(mcc_codes_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insert Data into: Transactions Table\n",
    "____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13305915 entries, 0 to 13305914\n",
      "Data columns (total 12 columns):\n",
      " #   Column            Dtype         \n",
      "---  ------            -----         \n",
      " 0   transaction_id    int64         \n",
      " 1   transaction_date  datetime64[ns]\n",
      " 2   user_id           int64         \n",
      " 3   card_id           int64         \n",
      " 4   amount            float64       \n",
      " 5   use_chip          object        \n",
      " 6   merchant_id       int64         \n",
      " 7   merchant_city     object        \n",
      " 8   merchant_state    object        \n",
      " 9   zip               object        \n",
      " 10  mcc_code          int64         \n",
      " 11  errors            object        \n",
      "dtypes: datetime64[ns](1), float64(1), int64(5), object(5)\n",
      "memory usage: 1.2+ GB\n"
     ]
    }
   ],
   "source": [
    "transactions_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Transactions data inserted successfully.\n"
     ]
    }
   ],
   "source": [
    "# Insert transactions data into the transactions table\n",
    "def insert_transactions_data(transactions_df):\n",
    "    # Connect to the database\n",
    "    conn = connect_to_db_with_db()\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Iterate over each row in the DataFrame and insert it into the transactions table\n",
    "    for index, row in transactions_df.iterrows():\n",
    "        cursor.execute(\"\"\"\n",
    "            INSERT INTO transactions (\n",
    "                transaction_id,\n",
    "                transaction_date,\n",
    "                user_id,\n",
    "                card_id,\n",
    "                amount,\n",
    "                use_chip,\n",
    "                merchant_id,\n",
    "                merchant_city,\n",
    "                merchant_state,\n",
    "                zip,\n",
    "                mcc_code,\n",
    "                errors\n",
    "            )\n",
    "            VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "        \"\"\", (\n",
    "            int(row['transaction_id']),\n",
    "            row['transaction_date'],  # assuming the DB accepts datetime objects\n",
    "            int(row['user_id']),\n",
    "            int(row['card_id']),\n",
    "            float(row['amount']),\n",
    "            row['use_chip'],\n",
    "            int(row['merchant_id']),\n",
    "            row['merchant_city'],\n",
    "            row['merchant_state'],\n",
    "            row['zip'],\n",
    "            int(row['mcc_code']),\n",
    "            row['errors']\n",
    "        ))\n",
    "\n",
    "    # Commit the transaction\n",
    "    conn.commit()\n",
    "\n",
    "    # Close the connection\n",
    "    conn.close()\n",
    "\n",
    "    print(\"âœ… Transactions data inserted successfully.\")\n",
    "\n",
    "# Call the function (assuming your DataFrame is named transactions_data)\n",
    "insert_transactions_data(transactions_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insert Data into:  Train_fraud_data Table\n",
    "_____\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 8914963 entries, 10649266 to 15151926\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Dtype \n",
      "---  ------  ----- \n",
      " 0   target  object\n",
      "dtypes: object(1)\n",
      "memory usage: 136.0+ MB\n"
     ]
    }
   ],
   "source": [
    "fraud_labels_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Fraud Labels data inserted successfully.\n"
     ]
    }
   ],
   "source": [
    "# Insert fraud labels data into the fraud_labels table\n",
    "def insert_fraud_labels_data(fraud_labels_df):\n",
    "    # Map 'No' to 0 and 'Yes' to 1\n",
    "    fraud_labels_df['target'] = fraud_labels_df['target'].map({'No': 0, 'Yes': 1})\n",
    "\n",
    "    # Connect to the database\n",
    "    conn = connect_to_db_with_db()\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Iterate over each row in the DataFrame and insert it into the table.\n",
    "    # Here, the DataFrame index is used as the transaction_id and the 'target'\n",
    "    # column is used as the is_fraud flag.\n",
    "    for transaction_id, row in fraud_labels_df.iterrows():\n",
    "        cursor.execute(\"\"\"\n",
    "            INSERT INTO fraud_labels (transaction_id, is_fraud)\n",
    "            VALUES (%s, %s)\n",
    "        \"\"\", (\n",
    "            int(transaction_id),  # Use index as transaction_id\n",
    "            int(row['target'])    # Convert the target value to int\n",
    "        ))\n",
    "\n",
    "    # Commit the transaction\n",
    "    conn.commit()\n",
    "\n",
    "    # Close the connection\n",
    "    conn.close()\n",
    "\n",
    "    print(\"âœ… Fraud Labels data inserted successfully.\")\n",
    "\n",
    "# Call the function (replace `fraud_labels_data` with your DataFrame variable name)\n",
    "insert_fraud_labels_data(fraud_labels_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ“š 3. Features Engineering \n",
    "___\n",
    "\n",
    "<div style=\"font-family: Avenir, sans-serif; font-size: 16px; line-height: 1.6; color: white; background-color: #333; padding: 10px; border-radius: 5px;\">\n",
    "In this section, we focus on feature engineeringâ€”the process of creating new, informative variables from the existing raw data. These engineered features are not directly available in the original dataset but are derived by combining and transforming columns through SQL queries. The goal is to enhance the predictive power of machine learning models and improve the accuracy of financial forecasts.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we reconnect to the SQL database to extract the data for feature engineering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_query(query):\n",
    "    \"\"\"\n",
    "    Connects to the 'financial_transactions_db' database,\n",
    "    executes the provided SQL query, and returns the results as a DataFrame.\n",
    "    \"\"\"\n",
    "    conn = mysql.connector.connect(\n",
    "        host=MYSQL_HOST,\n",
    "        user=MYSQL_USER,\n",
    "        password=MYSQL_PASSWORD,\n",
    "        database=\"financial_transactions_db\"\n",
    "    )\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(query)\n",
    "    result = cursor.fetchall()\n",
    "    columns = [desc[0] for desc in cursor.description]\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "    return pd.DataFrame(result, columns=columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective of this project is 4-fold:\n",
    "1. **Financial Forecasting:** Predict future revenue and expenses using historical transaction data.\n",
    "2. **Variance Analysis:** Compare budgeted vs. actual financial performance to identify key variance drivers.\n",
    "3. **Customer Insights:** Understand customer behavior through spending segmentation and clustering.\n",
    "4. **Business Intelligence:** Develop Power BI dashboards for real-time financial tracking and variance monitoring.\n",
    "\n",
    "Thus, feature engineering will focus on creating variables that capture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Financial Forecasting Features\n",
    "___\n",
    "- **Time-based Features:** Extract month, quarter, and year from transaction dates.\n",
    "- **Lag Features:** Compute lagged values of revenue and expenses to capture trends.\n",
    "- **Rolling Aggregations:** Calculate moving averages and cumulative sums for revenue and expenses.\n",
    "- **Monthly Aggregated Revenue & Expenses:** : Aggregate transaction amounts by month/year to create a time-series of revenue and expenses.\n",
    "- **Time-Based Features:** : Extract transaction month, year, quarter, and even day/hour from the transaction date to capture seasonal trends and peak spending times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'run_query' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 36\u001b[0m\n\u001b[1;32m      1\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;124mWITH monthly_data AS (\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     32\u001b[0m \n\u001b[1;32m     33\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# Execute the query and display the resulting DataFrame\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m df_metrics \u001b[38;5;241m=\u001b[39m \u001b[43mrun_query\u001b[49m(query)\n\u001b[1;32m     37\u001b[0m df_metrics\n",
      "\u001b[0;31mNameError\u001b[0m: name 'run_query' is not defined"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "\n",
    "WITH monthly_data AS (\n",
    "    SELECT \n",
    "        DATE_FORMAT(t.transaction_date, '%Y-%m-01') AS month_start,\n",
    "        YEAR(t.transaction_date) AS transaction_year,\n",
    "        MONTH(t.transaction_date) AS transaction_month,\n",
    "        QUARTER(t.transaction_date) AS transaction_quarter,\n",
    "        SUM(t.amount) AS total_amount,\n",
    "        AVG(DAY(t.transaction_date)) AS avg_transaction_day,\n",
    "        AVG(HOUR(t.transaction_date)) AS avg_transaction_hour\n",
    "    FROM transactions t\n",
    "    GROUP BY month_start, \n",
    "             transaction_year, \n",
    "             transaction_month, \n",
    "             transaction_quarter\n",
    ")\n",
    "SELECT\n",
    "    month_start,\n",
    "    transaction_year,\n",
    "    transaction_month,\n",
    "    transaction_quarter,\n",
    "    total_amount,\n",
    "    LAG(total_amount, 1) OVER (ORDER BY month_start) AS previous_month_amount,\n",
    "    LAG(total_amount, 2) OVER (ORDER BY month_start) AS two_months_ago_amount,\n",
    "    SUM(total_amount) OVER (ORDER BY month_start ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS cumulative_amount,\n",
    "    AVG(total_amount) OVER (ORDER BY month_start ROWS BETWEEN 2 PRECEDING AND CURRENT ROW) AS moving_avg_3_months,\n",
    "    avg_transaction_day,\n",
    "    avg_transaction_hour\n",
    "FROM monthly_data\n",
    "ORDER BY month_start;\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Execute the query and display the resulting DataFrame\n",
    "df_metrics = run_query(query)\n",
    "df_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 . Variance Analysis Features\n",
    "___\n",
    "- **Budgeted vs. Actual Features:**  Use the transaction-level query to understand individual discrepancies. This data can be used for detailed analysis or fed directly into predictive models.\n",
    "- **Variance by Customer:** : Analyze the customer-level variance query to identify high-variance spenders. This insight can help in segmenting customers or tailoring interventions for those with irregular spending patterns.\n",
    "- **Variance by Merchant:** : Evaluate the merchant category variance to detect spending deviations across different business types. This is particularly useful for spotting sector-specific trends or anomalies.\n",
    "- **Variance by Time:**\n",
    "Use the monthly aggregation to uncover seasonal trends and overall financial deviations over time. This time-series data is ideal for visualizations and further statistical analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Budgeted vs. Actual Features:** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "\n",
    "SELECT \n",
    "    t.transaction_id,\n",
    "    t.user_id,\n",
    "    t.amount AS actual_spending,\n",
    "    t.budgeted_expense,\n",
    "    (t.amount - t.budgeted_expense) AS variance,\n",
    "    CASE \n",
    "        WHEN t.budgeted_expense <> 0 THEN ((t.amount - t.budgeted_expense) / t.budgeted_expense) * 100 \n",
    "        ELSE NULL \n",
    "    END AS variance_pct\n",
    "FROM transactions t\n",
    "ORDER BY variance_pct DESC;\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Execute the query and display the resulting DataFrame\n",
    "df_metrics = run_query(query)\n",
    "df_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Variance by Customer:** : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "\n",
    "SELECT \n",
    "    t.user_id,\n",
    "    SUM(t.amount) AS total_actual_spending,\n",
    "    SUM(t.budgeted_expense) AS total_budgeted_expense,\n",
    "    (SUM(t.amount) - SUM(t.budgeted_expense)) AS total_variance,\n",
    "    CASE \n",
    "        WHEN SUM(t.budgeted_expense) <> 0 THEN ((SUM(t.amount) - SUM(t.budgeted_expense)) / SUM(t.budgeted_expense)) * 100 \n",
    "        ELSE NULL \n",
    "    END AS variance_pct_customer\n",
    "FROM transactions t\n",
    "GROUP BY t.user_id\n",
    "ORDER BY variance_pct_customer DESC;\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Execute the query and display the resulting DataFrame\n",
    "df_metrics = run_query(query)\n",
    "df_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Variance by Merchant:** : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "\n",
    "SELECT \n",
    "    mc.category_description,\n",
    "    SUM(t.amount) AS total_actual_spending,\n",
    "    SUM(t.budgeted_expense) AS total_budgeted_expense,\n",
    "    (SUM(t.amount) - SUM(t.budgeted_expense)) AS total_variance,\n",
    "    CASE \n",
    "        WHEN SUM(t.budgeted_expense) <> 0 THEN ((SUM(t.amount) - SUM(t.budgeted_expense)) / SUM(t.budgeted_expense)) * 100 \n",
    "        ELSE NULL \n",
    "    END AS variance_pct_merchant\n",
    "FROM transactions t\n",
    "LEFT JOIN mcc_codes mc ON t.mcc_code = mc.mcc_code\n",
    "GROUP BY mc.category_description\n",
    "ORDER BY variance_pct_merchant DESC;\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Execute the query and display the resulting DataFrame\n",
    "df_metrics = run_query(query)\n",
    "df_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Variance by Time:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "\n",
    "SELECT \n",
    "    YEAR(t.transaction_date) AS transaction_year,\n",
    "    MONTH(t.transaction_date) AS transaction_month,\n",
    "    SUM(t.amount) AS total_actual_spending,\n",
    "    SUM(t.budgeted_expense) AS total_budgeted_expense,\n",
    "    (SUM(t.amount) - SUM(t.budgeted_expense)) AS total_variance,\n",
    "    CASE \n",
    "        WHEN SUM(t.budgeted_expense) <> 0 THEN ((SUM(t.amount) - SUM(t.budgeted_expense)) / SUM(t.budgeted_expense)) * 100 \n",
    "        ELSE NULL \n",
    "    END AS variance_pct_time\n",
    "FROM transactions t\n",
    "GROUP BY transaction_year, transaction_month\n",
    "ORDER BY transaction_year, transaction_month;\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Execute the query and display the resulting DataFrame\n",
    "df_metrics = run_query(query)\n",
    "df_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 . Customer Spending & Segmentation\n",
    "____\n",
    "- **Total Spending & Average Transaction Value:**  \n",
    "  We aggregate transactions per customer to calculate the total amount spent and the average value per transaction. This involves combining the `transactions` table with the customer identifier, creating a summary metric that isn't directly available in the raw data.\n",
    "- **Credit Utilization:**  \n",
    "  By joining the `transactions` and `cards` tables, we compute the ratio of total spending to the credit limit of each card. This derived metric assesses how much of a customer's available credit is used, providing deeper insights into financial behavior.\n",
    "- **Spending Variance:**  \n",
    "  We calculate the difference between actual spending and budgeted expenses. The variance and its percentage give an indication of how much the actual behavior deviates from expected spending patterns.\n",
    " - **Chip vs. Non-Chip Transaction Ratio:**  \n",
    "  By analyzing the `use_chip` column in the transactions table, we determine the ratio of chip-enabled transactions to non-chip transactions. This ratio, obtained through conditional counts, offers insights into transaction security practices and customer preferences.\n",
    "\n",
    "- **Spending Distribution Across Merchant Categories:**  \n",
    "  Joining the `transactions` and `mcc_codes` tables allows us to aggregate spending by merchant category. This reveals which business sectors a customer frequents, a feature that emerges only through the integration of multiple data sources.\n",
    "- **Fraudulent Transaction Analysis:**  \n",
    "  By linking the `fraud_labels` table with transaction and merchant information, we isolate transactions flagged as fraudulent. This creates a focused dataset for risk modeling and anomaly detection.\n",
    "\n",
    "- **User Fraud Frequency:**  \n",
    "  Aggregating fraudulent transactions per user provides a metric indicating how frequently a user is involved in suspicious activity, enabling targeted risk assessments.\n",
    "\n",
    "- **Card Fraud Metrics:**  \n",
    "  Summarizing fraud occurrences at the card level allows us to derive a fraud count and total fraudulent spending per card. These features are critical for monitoring and preventing card misuse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Total Spending & Average Transaction Value:**  Total Spending, Average Transaction Value, Credit Utilization, Frequency of Transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "user_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "total_transactions",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "total_spending",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "avg_transaction_value",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "c284d229-defb-4eb6-9083-92280c920c92",
       "rows": [
        [
         "0",
         "96",
         "38617",
         "2445773.250000006",
         "63.334108035321385"
        ],
        [
         "1",
         "1686",
         "19810",
         "2167880.900000001",
         "109.43366481574967"
        ],
        [
         "2",
         "1340",
         "22023",
         "2039921.2300000037",
         "92.62685510602569"
        ],
        [
         "3",
         "840",
         "15095",
         "1956340.8400000038",
         "129.60191056641298"
        ],
        [
         "4",
         "464",
         "27619",
         "1882901.3499999829",
         "68.1741319381579"
        ],
        [
         "5",
         "490",
         "21831",
         "1711482.690000015",
         "78.39689844716298"
        ],
        [
         "6",
         "704",
         "20748",
         "1635022.0500000033",
         "78.80383892423382"
        ],
        [
         "7",
         "285",
         "32032",
         "1615458.99",
         "50.432660776723274"
        ],
        [
         "8",
         "488",
         "23990",
         "1611114.4199999918",
         "67.15774989578956"
        ],
        [
         "9",
         "1168",
         "30520",
         "1590822.749999994",
         "52.123943315858256"
        ],
        [
         "10",
         "989",
         "12069",
         "1538980.3500000054",
         "127.51515038528507"
        ],
        [
         "11",
         "52",
         "20949",
         "1535007.8000000026",
         "73.27355959711693"
        ],
        [
         "12",
         "630",
         "19619",
         "1467776.2700000016",
         "74.81402059228307"
        ],
        [
         "13",
         "1098",
         "48479",
         "1460166.8000000087",
         "30.119573423544395"
        ],
        [
         "14",
         "1888",
         "40105",
         "1436784.280000003",
         "35.82556489215816"
        ],
        [
         "15",
         "1575",
         "28314",
         "1425880.4000000143",
         "50.3595535777359"
        ],
        [
         "16",
         "1066",
         "18250",
         "1402519.6699999925",
         "76.85039287671192"
        ],
        [
         "17",
         "1651",
         "16983",
         "1367892.2400000042",
         "80.54479420597092"
        ],
        [
         "18",
         "1797",
         "30326",
         "1353263.3700000008",
         "44.62386631932998"
        ],
        [
         "19",
         "371",
         "18429",
         "1345198.2900000017",
         "72.99355852189493"
        ],
        [
         "20",
         "1802",
         "18351",
         "1344883.4999999965",
         "73.2866601275133"
        ],
        [
         "21",
         "1776",
         "41350",
         "1331738.889999996",
         "32.20650278113654"
        ],
        [
         "22",
         "1988",
         "17096",
         "1323029.8200000047",
         "77.38826743097829"
        ],
        [
         "23",
         "1595",
         "26482",
         "1316382.6999999934",
         "49.708583188580675"
        ],
        [
         "24",
         "1648",
         "21075",
         "1310148.3500000034",
         "62.16599525504168"
        ],
        [
         "25",
         "303",
         "17912",
         "1304581.1800000109",
         "72.83280370701267"
        ],
        [
         "26",
         "1169",
         "29906",
         "1297296.619999988",
         "43.37914197819796"
        ],
        [
         "27",
         "1692",
         "21518",
         "1273461.970000002",
         "59.18124221581941"
        ],
        [
         "28",
         "1654",
         "28070",
         "1264344.3600000024",
         "45.04254934093347"
        ],
        [
         "29",
         "1963",
         "42462",
         "1253911.4600000007",
         "29.530202534030444"
        ],
        [
         "30",
         "1989",
         "16290",
         "1251417.7300000016",
         "76.82122344996941"
        ],
        [
         "31",
         "165",
         "13876",
         "1245012.6999999995",
         "89.72417843759004"
        ],
        [
         "32",
         "1528",
         "21808",
         "1211433.3800000022",
         "55.54995322817325"
        ],
        [
         "33",
         "1403",
         "19733",
         "1205753.6800000025",
         "61.10341458470595"
        ],
        [
         "34",
         "208",
         "30474",
         "1191648.340000005",
         "39.103771739843964"
        ],
        [
         "35",
         "1696",
         "30672",
         "1181415.110000001",
         "38.517707029212346"
        ],
        [
         "36",
         "1811",
         "19194",
         "1158301.1099999999",
         "60.34704126289465"
        ],
        [
         "37",
         "1543",
         "20536",
         "1142972.9700000044",
         "55.6570398324895"
        ],
        [
         "38",
         "1487",
         "12982",
         "1141147.2400000028",
         "87.90226775535378"
        ],
        [
         "39",
         "1241",
         "14265",
         "1127821.1199999996",
         "79.06211847178406"
        ],
        [
         "40",
         "1587",
         "11444",
         "1121516.9499999995",
         "98.00043254106951"
        ],
        [
         "41",
         "598",
         "25656",
         "1113780.4799999944",
         "43.41208606173973"
        ],
        [
         "42",
         "856",
         "12859",
         "1110181.439999998",
         "86.33497472587278"
        ],
        [
         "43",
         "1102",
         "17775",
         "1109536.4199999992",
         "62.42117693389588"
        ],
        [
         "44",
         "430",
         "20998",
         "1109182.9400000041",
         "52.82326602533594"
        ],
        [
         "45",
         "1253",
         "19846",
         "1106437.8999999955",
         "55.75117907890736"
        ],
        [
         "46",
         "1908",
         "14371",
         "1100362.6699999976",
         "76.56827430241442"
        ],
        [
         "47",
         "708",
         "8681",
         "1094355.6399999983",
         "126.06331528625715"
        ],
        [
         "48",
         "1238",
         "10977",
         "1086471.1800000046",
         "98.97705930582168"
        ],
        [
         "49",
         "408",
         "18777",
         "1079323.109999998",
         "57.48112637801555"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 1219
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>total_transactions</th>\n",
       "      <th>total_spending</th>\n",
       "      <th>avg_transaction_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>96</td>\n",
       "      <td>38617</td>\n",
       "      <td>2445773.25</td>\n",
       "      <td>63.334108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1686</td>\n",
       "      <td>19810</td>\n",
       "      <td>2167880.90</td>\n",
       "      <td>109.433665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1340</td>\n",
       "      <td>22023</td>\n",
       "      <td>2039921.23</td>\n",
       "      <td>92.626855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>840</td>\n",
       "      <td>15095</td>\n",
       "      <td>1956340.84</td>\n",
       "      <td>129.601911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>464</td>\n",
       "      <td>27619</td>\n",
       "      <td>1882901.35</td>\n",
       "      <td>68.174132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1214</th>\n",
       "      <td>19</td>\n",
       "      <td>3268</td>\n",
       "      <td>54420.25</td>\n",
       "      <td>16.652463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1215</th>\n",
       "      <td>1942</td>\n",
       "      <td>5564</td>\n",
       "      <td>53036.53</td>\n",
       "      <td>9.532087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1216</th>\n",
       "      <td>1016</td>\n",
       "      <td>2170</td>\n",
       "      <td>52388.75</td>\n",
       "      <td>24.142281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1217</th>\n",
       "      <td>1331</td>\n",
       "      <td>7382</td>\n",
       "      <td>39423.45</td>\n",
       "      <td>5.340484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1218</th>\n",
       "      <td>1289</td>\n",
       "      <td>2511</td>\n",
       "      <td>26605.34</td>\n",
       "      <td>10.595516</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1219 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id  total_transactions  total_spending  avg_transaction_value\n",
       "0          96               38617      2445773.25              63.334108\n",
       "1        1686               19810      2167880.90             109.433665\n",
       "2        1340               22023      2039921.23              92.626855\n",
       "3         840               15095      1956340.84             129.601911\n",
       "4         464               27619      1882901.35              68.174132\n",
       "...       ...                 ...             ...                    ...\n",
       "1214       19                3268        54420.25              16.652463\n",
       "1215     1942                5564        53036.53               9.532087\n",
       "1216     1016                2170        52388.75              24.142281\n",
       "1217     1331                7382        39423.45               5.340484\n",
       "1218     1289                2511        26605.34              10.595516\n",
       "\n",
       "[1219 rows x 4 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the query to aggregate customer metrics\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    t.user_id,\n",
    "    COUNT(t.transaction_id) AS total_transactions,\n",
    "    SUM(t.amount) AS total_spending,\n",
    "    AVG(t.amount) AS avg_transaction_value\n",
    "FROM transactions t\n",
    "GROUP BY t.user_id\n",
    "ORDER BY total_spending DESC;\n",
    "\"\"\"\n",
    "\n",
    "# Execute the query and display the resulting DataFrame\n",
    "df_metrics = run_query(query)\n",
    "df_metrics\n",
    "\n",
    "\n",
    "# Save the DataFrame to a CSV file without the index column\n",
    "df_metrics.to_csv(\"customer_metrics.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Credit Utilization:** Credit Utilization Rate (Total Spending / Credit Limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "\n",
    "\n",
    "SELECT \n",
    "    u.user_id,\n",
    "    SUM(t.amount) AS total_spending,\n",
    "    c.credit_limit,\n",
    "    (SUM(t.amount) / c.credit_limit) * 100 AS credit_utilization_pct\n",
    "FROM transactions t\n",
    "JOIN cards c ON t.card_id = c.card_id\n",
    "JOIN users u ON t.user_id = u.user_id\n",
    "GROUP BY u.user_id, c.credit_limit\n",
    "ORDER BY credit_utilization_pct DESC;\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Execute the query and display the resulting DataFrame\n",
    "df_metrics = run_query(query)\n",
    "df_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Spending Variance:**: Variance Between Expected and Actual Spending "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "\n",
    "\n",
    "SELECT \n",
    "    t.user_id,\n",
    "    t.transaction_id,\n",
    "    t.amount AS actual_spending,\n",
    "    t.budgeted_expense,\n",
    "    (t.amount - t.budgeted_expense) AS variance,\n",
    "    ((t.amount - t.budgeted_expense) / t.budgeted_expense) * 100 AS variance_pct\n",
    "FROM transactions t\n",
    "WHERE t.budgeted_expense > 0 -- Avoid division by zero\n",
    "ORDER BY variance_pct DESC;\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Execute the query and display the resulting DataFrame\n",
    "df_metrics = run_query(query)\n",
    "df_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Chip vs. Non-Chip Transaction Ratio:**  Ratio of Chip to Non-Chip Transactions per Customer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "\n",
    "\n",
    "SELECT \n",
    "    t.user_id,\n",
    "    SUM(CASE WHEN t.use_chip = 'Yes' THEN 1 ELSE 0 END) AS chip_transactions,\n",
    "    SUM(CASE WHEN t.use_chip = 'No' THEN 1 ELSE 0 END) AS non_chip_transactions,\n",
    "    (SUM(CASE WHEN t.use_chip = 'Yes' THEN 1 ELSE 0 END) * 1.0 / NULLIF(SUM(CASE WHEN t.use_chip = 'No' THEN 1 ELSE 0 END), 0)) AS chip_to_nonchip_ratio\n",
    "FROM transactions t\n",
    "GROUP BY t.user_id\n",
    "ORDER BY chip_to_nonchip_ratio DESC;\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Execute the query and display the resulting DataFrame\n",
    "df_metrics = run_query(query)\n",
    "df_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Spending Distribution Across Merchant Categories:** Distribution of Spending Across Merchant Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "\n",
    "SELECT \n",
    "    t.user_id,\n",
    "    mc.category_description,\n",
    "    COUNT(t.transaction_id) AS total_transactions,\n",
    "    SUM(t.amount) AS total_spent\n",
    "FROM transactions t\n",
    "JOIN mcc_codes mc ON t.mcc_code = mc.mcc_code\n",
    "GROUP BY t.user_id, mc.category_description\n",
    "ORDER BY t.user_id, total_spent DESC;\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Execute the query and display the resulting DataFrame\n",
    "df_metrics = run_query(query)\n",
    "df_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Fraudulent Transaction Analysis:** : High-Risk Transactions: Fraud Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "\n",
    "SELECT \n",
    "    t.transaction_id,\n",
    "    t.user_id,\n",
    "    t.card_id,\n",
    "    t.amount,\n",
    "    f.is_fraud,\n",
    "    mc.category_description AS merchant_category,\n",
    "    t.merchant_city,\n",
    "    t.merchant_state\n",
    "FROM transactions t\n",
    "JOIN fraud_labels f ON t.transaction_id = f.transaction_id\n",
    "JOIN mcc_codes mc ON t.mcc_code = mc.mcc_code\n",
    "WHERE f.is_fraud = 1\n",
    "ORDER BY t.amount DESC;\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Execute the query and display the resulting DataFrame\n",
    "df_metrics = run_query(query)\n",
    "df_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **User Fraud Frequency:** Users with the Highest Number of Fraudulent Transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "\n",
    "SELECT \n",
    "    t.user_id,\n",
    "    COUNT(f.transaction_id) AS fraudulent_transactions,\n",
    "    SUM(t.amount) AS fraudulent_spending\n",
    "FROM transactions t\n",
    "JOIN fraud_labels f ON t.transaction_id = f.transaction_id\n",
    "WHERE f.is_fraud = 1\n",
    "GROUP BY t.user_id\n",
    "ORDER BY fraudulent_spending DESC;\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Execute the query and display the resulting DataFrame\n",
    "df_metrics = run_query(query)\n",
    "df_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Card Fraud Metrics:** Cards That Appeared in Fraudulent Transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "\n",
    "SELECT \n",
    "    c.card_id,\n",
    "    c.user_id,\n",
    "    c.card_type,\n",
    "    COUNT(f.transaction_id) AS fraud_count,\n",
    "    SUM(t.amount) AS fraud_total_amount\n",
    "FROM cards c\n",
    "JOIN transactions t ON c.card_id = t.card_id\n",
    "JOIN fraud_labels f ON t.transaction_id = f.transaction_id\n",
    "WHERE f.is_fraud = 1\n",
    "GROUP BY c.card_id, c.user_id, c.card_type\n",
    "ORDER BY fraud_total_amount DESC;\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Execute the query and display the resulting DataFrame\n",
    "df_metrics = run_query(query)\n",
    "df_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Integrated Data Quality\n",
    "___\n",
    "\n",
    "Ensuring data quality is fundamental for reliable feature engineering. Integrated data quality checks confirm that the relationships between tables are maintained and that the data is free from duplicates or orphan records.\n",
    "\n",
    "- **Orphan Transaction Check:**  \n",
    "  We verify that all transactions have corresponding entries in the `users` and `cards` tables, ensuring the integrity of our joined datasets.\n",
    "  \n",
    "- **Duplicate Transaction Check:**  \n",
    "  Identifying duplicate transaction IDs helps maintain a clean dataset, which is crucial for accurate analysis and reliable model training.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Orphan Transaction Check:**  Verify Transactions with Missing User or Card Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "\n",
    "SELECT transaction_id \n",
    "FROM transactions\n",
    "WHERE user_id NOT IN (SELECT user_id FROM users) \n",
    "OR card_id NOT IN (SELECT card_id FROM cards);\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Execute the query and display the resulting DataFrame\n",
    "df_metrics = run_query(query)\n",
    "df_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Duplicate Transaction Check:**  Identify Duplicate Transaction IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "\n",
    "SELECT transaction_id, COUNT(*) \n",
    "FROM transactions\n",
    "GROUP BY transaction_id\n",
    "HAVING COUNT(*) > 1;\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Execute the query and display the resulting DataFrame\n",
    "df_metrics = run_query(query)\n",
    "df_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 Business Intelligence Features\n",
    "___\n",
    "\n",
    "\n",
    "- **Revenue & Expense Trends:**  \n",
    "  By aggregating transaction amounts over time, we create a time-series of revenue and expenses. This data is essential for forecasting and variance analysis.\n",
    "- **Customer Segmentation:**\n",
    "  Clustering algorithms like K-Means or DBSCAN can group customers based on spending patterns, transaction frequency, and merchant preferences. These segments provide insights for targeted marketing or risk management.\n",
    "- **Interactive Dashboards:**\n",
    "  Power BI dashboards can visualize revenue, expenses, and variance trends, offering real-time insights into financial performance. These interactive reports are crucial for decision-makers to monitor key metrics and identify areas for improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ“š 4. Data Visualisation \n",
    "___\n",
    "\n",
    "<div style=\"font-family: Avenir, sans-serif; font-size: 16px; line-height: 1.6; color: white; background-color: #333; padding: 10px; border-radius: 5px;\">\n",
    "This section focuses on data visualization using Power BI, and python libraries such as Matplotlib, Seaborn, and Plotly. The goal is to create interactive dashboards and visualizations that provide insights into revenue trends, expense patterns, customer segmentation, and financial variances. The visualizations will be used to facilitate data-driven decision-making and enhance financial analysis.\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine-learning-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
